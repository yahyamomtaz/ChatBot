{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import requests\n",
    "import os\n",
    "\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from langchain.document_loaders import UnstructuredFileLoader\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "os.environ[\"SERPAPI_API_KEY\"] = \"a04ee48f71a634d065405ad27fb43c7d189c2086be2fd931d1ff3e389ce7fe5f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredFileLoader('/Users/yaya/Desktop/Text Mining Project/ChatBot/DIVISION OF ASSETS AFTER DIVORCE.txt')\n",
    "document = loader.load()\n",
    "docs = char_text_splitter.split_documents (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis civil code outlines the statutory matrimonial property regime in the absence of a different agreement. This regime is governed by community of property and outlined in Article 177 and following. The spouses cannot waive either their rights or their duties under the law as a result of marriage and may not agree in a general way that their property relationships shall be governed by laws to which they are not subject or custom, but must set out in concrete terms the content of the agreements by which they intend to regulate these relationships. Marital agreements must be declared in the marriage ceremony or concluded at any time by an authentic instrument, with the consent of all the persons who were parties to the agreements, or their heirs, in order to be valid and enforceable against third parties. If the date, notary, and particulars of the contracting parties are not included in the contract, it cannot be enforced against third parties. Agreements may be amended with the consent of the parties, and homologation by the court is required for the amendment to be effective against third parties. An annotation in the margin of the marriage certificate is also necessary for any agreed amendment to be effective against third parties.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = load_summarize_chain(llm=llm, chain_type=\"refine\")\n",
    "model.run(docs[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name=\"text-davinci-003\")\n",
    "llm(\"explain large language models in one sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tools, \n",
    "                         llm, \n",
    "                         agent=\"zero-shot-react-description\", \n",
    "                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Hi How are you today?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"what is PROHIBITION OF AGREEMENTS ON INHERITANCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = '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'\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "\n",
    "\n",
    "# Define your law data as a list of strings or paragraphs\n",
    "law_data = [\n",
    "    \"Law 1: STATUTORY MATRIMONIAL PROPERTY REGIME\",\n",
    "    \"Law 2: ...\",\n",
    "    \"Law 3: ...\"\n",
    "    # Add more law data here\n",
    "]\n",
    "\n",
    "# Function to get AI-generated response based on user input\n",
    "def get_ai_response(user_input):\n",
    "    # Format the user input and concatenate with the law data\n",
    "    prompt = f\"User: {user_input}\\nData: \" + \"\\n\".join(law_data)\n",
    "\n",
    "    # Generate the AI response using OpenAI API\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    # Extract and return the generated answer\n",
    "    answer = response.choices[0].text.strip().split('\\n')[0]\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "user_query = input(\"Enter your query: \")\n",
    "response = get_ai_response(user_query)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Function to read law data from text files\n",
    "def read_law_data(file_paths):\n",
    "    law_data = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            law_content = file.read().strip()\n",
    "            law_data.append(law_content)\n",
    "    return law_data\n",
    "\n",
    "# Function to get AI-generated response based on user input and law data\n",
    "def get_ai_response(user_input, law_data):\n",
    "    prompt = f\"User: {user_input}\\nData: \" + \"\\n\".join(law_data)\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=100,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    answer = response.choices[0].text.strip().split('\\n')[0]\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "file_paths = ['civil_code.txt', 'other_law.txt']\n",
    "law_data = read_law_data(file_paths)\n",
    "\n",
    "user_query = input(\"Enter your query: \")\n",
    "response = get_ai_response(user_query, law_data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# Set up your OpenAI API credentials\n",
    "openai.api_key = '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'\n",
    "\n",
    "# Function to read law data from text files\n",
    "def read_law_data(file_paths):\n",
    "    law_data = []\n",
    "    for file_path in file_paths:\n",
    "        with open(file_path, 'r') as file:\n",
    "            law_content = file.read().strip()\n",
    "            law_data.append(law_content)\n",
    "    return law_data\n",
    "\n",
    "# Function to get AI-generated response based on user input and law data\n",
    "def get_ai_response(user_input, law_data):\n",
    "    prompt = f\"User: {user_input}\\nData: \" + \"\\n\".join(law_data)\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=prompt,\n",
    "        max_tokens=1000,\n",
    "        temperature=0.7\n",
    "    )\n",
    "    answer = response.choices[0].text.strip().split('\\n')[0]\n",
    "    return answer\n",
    "\n",
    "# Example usage\n",
    "file_paths = ['/Users/yaya/Desktop/Text Mining Project/ChatBot/DIVISION OF ASSETS AFTER DIVORCE.txt']\n",
    "law_data = read_law_data(file_paths)\n",
    "\n",
    "user_query = input(\"Enter your query: \")\n",
    "response = get_ai_response(user_query, law_data)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0 (from sentence_transformers)\n",
      "  Using cached transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "Requirement already satisfied: tqdm in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from sentence_transformers) (4.65.0)\n",
      "Collecting torch>=1.6.0 (from sentence_transformers)\n",
      "  Using cached torch-2.0.1-cp310-none-macosx_10_9_x86_64.whl (143.4 MB)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Using cached torchvision-0.15.2-cp310-cp310-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "Requirement already satisfied: numpy in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from sentence_transformers) (1.23.5)\n",
      "Requirement already satisfied: scikit-learn in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from sentence_transformers) (1.10.1)\n",
      "Requirement already satisfied: nltk in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from sentence_transformers) (3.8.1)\n",
      "Collecting sentencepiece (from sentence_transformers)\n",
      "  Using cached sentencepiece-0.1.99-cp310-cp310-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "Collecting huggingface-hub>=0.4.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Collecting fsspec (from huggingface-hub>=0.4.0->sentence_transformers)\n",
      "  Using cached fsspec-2023.6.0-py3-none-any.whl (163 kB)\n",
      "Requirement already satisfied: requests in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.5.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.0)\n",
      "Collecting sympy (from torch>=1.6.0->sentence_transformers)\n",
      "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Requirement already satisfied: networkx in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.13.3-cp310-cp310-macosx_10_11_x86_64.whl (4.0 MB)\n",
      "Collecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence_transformers)\n",
      "  Using cached safetensors-0.3.1-cp310-cp310-macosx_10_11_x86_64.whl (400 kB)\n",
      "Requirement already satisfied: click in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yaya/anaconda3/envs/tensorflow/lib/python3.10/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.12.7)\n",
      "Collecting mpmath>=0.19 (from sympy->torch>=1.6.0->sentence_transformers)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=a5a745b471be0e78ab3cbb0682614379010d466b712185f4debf604f8ddec676\n",
      "  Stored in directory: /Users/yaya/Library/Caches/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, safetensors, mpmath, sympy, fsspec, torch, huggingface-hub, transformers, torchvision, sentence_transformers\n",
      "Successfully installed fsspec-2023.6.0 huggingface-hub-0.16.4 mpmath-1.3.0 safetensors-0.3.1 sentence_transformers-2.2.2 sentencepiece-0.1.99 sympy-1.12 tokenizers-0.13.3 torch-2.0.1 torchvision-0.15.2 transformers-4.30.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
